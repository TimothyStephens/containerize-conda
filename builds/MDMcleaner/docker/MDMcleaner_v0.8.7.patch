--- read_gtdb_taxonomy.py	2023-01-12 05:33:49.000000000 -0500
+++ read_gtdb_taxonomy.py	2025-02-03 15:26:07.779470307 -0500
@@ -630,11 +630,11 @@
 			the seqids in their taxid-lookuptables as well as the protein files have a "RS_" or "GB_" prefix, but the genomic files do not.
 			have to remove that prefix here
 	"""
-	import re
+	import re, random
 	assemblyIDpattern = re.compile("GC._\d+\.\d")
 	headerdict = _concat_fastas(contig_fastalist, outfastahandle, return_headerdict = True, remove_prodigalIDs = False, remove_descriptions = True)
 	from mdmcleaner import getdb #todo: delete this. is only for debuggung
-	getdb.dict2jsonfile(headerdict, "delme_headerdict.json.gz") #todo: delete this. is only for debuggung (or keep it as additional progress saving point
+	getdb.dict2jsonfile(headerdict, "delme_headerdict_" + str(random.randint(1, 1000000)) + ".json.gz") #todo: delete this. is only for debuggung (or keep it as additional progress saving point
 	outaccfile = openfile(acc2taxidoutfilename, "wt")
 	linecounter = contigcounter = 0
 	reptuple_list = [] #todo: this is only for checking sanity of gtdb downloads (which genomes are considered "representative" and have seqdate provided? which are missing? are all species/genera/phyla covered? which are missing)? comment this out later
@@ -657,7 +657,7 @@
 				sys.stderr.flush()
 		inaccfile.close()
 	outaccfile.close()
-	with open("delmetemp_repcheckfile.tsv", "wt") as repcheckfile: #todo: this is only for checking sanity of gtdb downloads (which genomes are considered "representative" and have seqdate provided? which are missing? are all species/genera/phyla covered? which are missing)? comment this out later
+	with open("delmetemp_repcheckfile_" + str(random.randint(1, 1000000)) + ".tsv", "wt") as repcheckfile: #todo: this is only for checking sanity of gtdb downloads (which genomes are considered "representative" and have seqdate provided? which are missing? are all species/genera/phyla covered? which are missing)? comment this out later
 		repcheckfile.write("{}\n".format("\n".join(["{}\t{}".format(x[0], x[1]) for x in reptuple_list]))) #todo: this is only for checking sanity of gtdb downloads (which genomes are considered "representative" and have seqdate provided? which are missing? are all species/genera/phyla covered? which are missing)? comment this out later
 	sys.stderr.write("\r\tassigned {} contigs to {} taxids\n".format(contigcounter, linecounter))
 	sys.stderr.flush()	
--- read_ncbi_taxonomy.py	2023-01-12 05:33:49.000000000 -0500
+++ read_ncbi_taxonomy.py	2025-02-03 15:25:48.731321060 -0500
@@ -64,7 +64,8 @@
 		
 	max_attempts = 10
 	ftpfilelist = ("ftp://" + ncbi_ftp_server + "/" + _dbsource_dict[dbtype], "ftp://" + ncbi_ftp_server + "/" +  _dbsource_dict[dbtype] + ".md5")
-	outfilenamelist = tuple((os.path.join(targetdir, "delmetemp_" + os.path.basename(f)) for f in ftpfilelist ))
+	import random
+	outfilenamelist = tuple((os.path.join(targetdir, "delmetemp_" + str(random.randint(1, 1000000)) + "_" + os.path.basename(f)) for f in ftpfilelist ))
 	current_attempts = 0
 	
 	while current_attempts < max_attempts:
--- blasthandler.py	2023-01-12 05:33:49.000000000 -0500
+++ blasthandler.py	2025-02-03 15:25:19.731093677 -0500
@@ -843,7 +843,8 @@
 	outfmt = re.sub(" std ", " qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore ", outfmt).strip().split() #blast allows "std" keyword in outfmt, diamond doesn't
 	if type(query) == list: #list indicates a list of seqrecords
 		# ~ print("QUERY IS A LIST")
-		tempname="delme_tempinput_mdmcleaner_diamondblastx.faa" # todo: figure out a better solution until a future diamond version hopefully may accept input from stdin...
+		import random
+		tempname="delme_tempinput_mdmcleaner_diamondblastx_" + str(random.randint(1, 1000000)) + ".faa" # todo: figure out a better solution until a future diamond version hopefully may accept input from stdin...
 		misc.write_fasta(query, tempname)
 		query = tempname
 	# ~ else:
--- getmarkers.py	2023-01-12 05:33:49.000000000 -0500
+++ getmarkers.py	2025-02-03 15:24:53.518887983 -0500
@@ -157,7 +157,8 @@
 	subfastas=list(subfastas)
 	for i in range(len(subfastas)):
 		if misc.has_gzip_suffix(subfastas[i]):
-			tempfilename = os.path.join(outdirectory, "delme_aragorn_tempfile_{}.fa".format(len(tempfilelist)))
+			import random
+			tempfilename = os.path.join(outdirectory, "delme_aragorn_tempfile_{}_{}.fa".format(len(tempfilelist), str(random.randint(1, 1000000))))
 			misc.unixzcat(subfastas[i], outfilename=tempfilename)
 			subfastas[i] = tempfilename
 			tempfilelist.append(tempfilename)
--- getdb.py	2023-01-12 05:33:49.000000000 -0500
+++ getdb.py	2025-02-11 12:46:03.309350777 -0500
@@ -47,9 +47,9 @@
 #todo: find common names for gtdb and ncbi dbs to simplify things
 #todo: find actual names for ncbi dbs
 dbfiles = { "gtdb" : {	"protblastdbs" : ["gtdbplus_protdb.dmnd"], \
-						"nucblastdbs" : ["concat_refgenomes", "SILVA_138.1_SSURef_NR99_tax_silva", "SILVA_138.1_LSURef_NR99_tax_silva"] ,\
-						"ssu_nucblastdbs" : ["concat_refgenomes", "SILVA_138.1_SSURef_NR99_tax_silva"], \
-						"lsu_nucblastdbs" : ["concat_refgenomes", "SILVA_138.1_LSURef_NR99_tax_silva"], \
+						"nucblastdbs" : ["concat_refgenomes", "SILVA_138.2_SSURef_NR99_tax_silva", "SILVA_138.2_LSURef_NR99_tax_silva"] ,\
+						"ssu_nucblastdbs" : ["concat_refgenomes", "SILVA_138.2_SSURef_NR99_tax_silva"], \
+						"lsu_nucblastdbs" : ["concat_refgenomes", "SILVA_138.2_LSURef_NR99_tax_silva"], \
 						"genome_nucblastdbs" : ["concat_refgenomes"], \
 						"mdmdbs" : ["gtdb_all.accession2taxid.sorted", "gtdb_taxonomy_br.json.gz", "gtdb_lcawalkdb_br.db"] },\
 			"ncbi" : {  "protblastdbs" : ["nr"], \
--- review_refdbcontams.py	2023-01-12 05:33:49.000000000 -0500
+++ review_refdbcontams.py	2025-02-11 12:50:19.907302186 -0500
@@ -302,7 +302,7 @@
 			blastrecords = [self.blastxjobs[x].seqrecord[0] for x in self.blastxjobs if len(self.blastxjobs[x].seqrecord[0]) < 100000] #for now skipping reference contigs larger than 100 kb (takes too long to blastx). TODO: in such cases, search for ribosomal & other markergenes to verify classification!
 			sys.stderr.write("\nblasting {} entries with blastx against reference proteins (another {} entries were too long to blastx efficiently\n".format(len(blastrecords), len(self.blastxjobs) - len(blastrecords)))
 			if len(blastrecords) == 0:
-				return
+				return [None]
 			basic_blastarglist = [ (blastrecords, blastdb, "diamond blastx") for blastdb in self.blastxdbs ]
 			# ~ import pdb; pdb.set_trace()
 			import time
